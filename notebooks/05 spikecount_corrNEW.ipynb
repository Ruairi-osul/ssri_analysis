{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ephys_queries import (\n",
    "    select_spike_times\n",
    ")\n",
    "from ephys_queries import db_setup_core\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spiketimes.df.correlate import spike_count_correlation_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path(\".\").absolute().parent / \"data\"\n",
    "dfb = pd.read_csv(data_dir / \"baseline.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "engine, metadata = db_setup_core()\n",
    "group_names = [\"acute_citalopram\", \"acute_saline\", \"shock\", \n",
    "               \"sham\", \"acute_cit\", \"acute_sal\"]\n",
    "block_name = \"pre\"\n",
    "fs = 30000\n",
    "\n",
    "df_spiketimes = (\n",
    "    select_spike_times(\n",
    "        engine, metadata, \n",
    "        block_name=block_name, \n",
    "        group_names=group_names,\n",
    "    )\n",
    "    .assign(\n",
    "        spiketimes= lambda x: x[\"spike_time_samples\"].divide(fs)\n",
    "    )\n",
    "    .drop(\"spike_time_samples\", axis=1)\n",
    "    .merge(dfb[[\"cluster\", \"neuron_id\", \"session_name\", \"group_name\"]])\n",
    "    .loc[lambda x: x[\"cluster\"] != \"no_baseline\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_names = df_spiketimes[\"session_name\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0%\n",
      "50.0%\n"
     ]
    }
   ],
   "source": [
    "big_frames = []\n",
    "# BINS = np.round(np.geomspace(0.01, 5, 15), 3)\n",
    "BINS = np.array([0.2, 1])\n",
    "NBOOT = 1000\n",
    "MIN_FR = 0.5\n",
    "for i, BIN in enumerate(BINS):\n",
    "    print(f\"{(i/len(BINS) * 100)}%\") \n",
    "    frames = []\n",
    "    for session in session_names:\n",
    "        frames.append(\n",
    "            df_spiketimes\n",
    "            .loc[lambda x: x[\"session_name\"]==session]\n",
    "            .pipe(\n",
    "                lambda x: spike_count_correlation_test(\n",
    "                    x, \n",
    "                    n_boot=NBOOT,\n",
    "                    binsize=BIN, \n",
    "                    min_firing_rate=MIN_FR,\n",
    "                    spiketimes_col=\"spiketimes\", \n",
    "                    spiketrain_col=\"neuron_id\",\n",
    "                    use_multiprocessing=True,\n",
    "                    max_cores=10\n",
    "                )\n",
    "            )\n",
    "            .assign(session_name=session,\n",
    "                   min_fr=MIN_FR,\n",
    "                   n_boot=NBOOT)\n",
    "        )\n",
    "    big_frames.append(\n",
    "        pd.concat(frames).assign(binsize=BIN)\n",
    "    )\n",
    "df = pd.concat(big_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-6b766986f235>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# df =\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m df_done = (\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mdf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdfb\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"neuron_id\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"cluster\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mleft_on\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"spiketrain_1\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mright_on\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"neuron_id\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"neuron_id\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# df =\n",
    "df_done = (\n",
    "    df\n",
    "    .merge(dfb[[\"neuron_id\", \"cluster\"]], left_on=\"spiketrain_1\", right_on=\"neuron_id\")\n",
    "    .drop(\"neuron_id\", axis=1)\n",
    "    .rename(columns={\"cluster\": \"spiketrain_1_cluster\"})\n",
    "    .merge(dfb[[\"neuron_id\", \"cluster\"]], left_on=\"spiketrain_2\", right_on=\"neuron_id\")\n",
    "    .drop(\"neuron_id\", axis=1)\n",
    "    .rename(columns={\"cluster\": \"spiketrain_2_cluster\"})\n",
    "    .assign(has_sr=lambda x: \n",
    "                x.apply(lambda y: (y.spiketrain_1_cluster == \"slow_regular\") or (y.spiketrain_2_cluster== \"slow_regular\"),\n",
    "                       axis=1),\n",
    "            has_sir=lambda x: \n",
    "                x.apply(lambda y: (y.spiketrain_1_cluster == \"slow_irregular\") or (y.spiketrain_2_cluster== \"slow_irregular\"),\n",
    "                       axis=1),\n",
    "            has_ff=lambda x: \n",
    "                x.apply(lambda y: (y.spiketrain_1_cluster == \"fast_firing\") or (y.spiketrain_2_cluster== \"fast_firing\"),\n",
    "                       axis=1)\n",
    "           )\n",
    "    .assign(comb= lambda x: x.apply(lambda y: \n",
    "                                    \"sr_sr\" if y.has_sr and (not y.has_sir) and (not y.has_ff)\n",
    "                                   else \"sr_sir\" if y.has_sr and y.has_sir and (not y.has_ff)\n",
    "                                   else \"sr_ff\" if y.has_sr and (not y.has_sir) and y.has_ff\n",
    "                                   else \"sir_sir\" if (not y.has_sr) and y.has_sir and (not y.has_ff)\n",
    "                                   else \"sir_ff\" if (not y.has_sr) and y.has_sir and y.has_ff\n",
    "                                   else \"ff_ff\", axis=1\n",
    "                                   ))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_done.to_csv(data_dir / \"rsctest_LC_sizes.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

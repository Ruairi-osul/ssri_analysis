{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ephys_queries import (\n",
    "    select_spike_times\n",
    ")\n",
    "from ephys_queries import db_setup_core\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spiketimes.df.correlate import cross_corr_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path(\".\").absolute().parent / \"data\"\n",
    "dfb = pd.read_csv(data_dir / \"baseline.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "engine, metadata = db_setup_core()\n",
    "group_names = [\"acute_citalopram\", \"acute_saline\", \"shock\", \n",
    "               \"sham\", \"acute_cit\", \"acute_sal\"]\n",
    "block_name = \"pre\"\n",
    "fs = 30000\n",
    "\n",
    "df_spiketimes = (\n",
    "    select_spike_times(\n",
    "        engine, metadata, \n",
    "        block_name=block_name, \n",
    "        group_names=group_names,\n",
    "    )\n",
    "    .assign(\n",
    "        spiketimes= lambda x: x[\"spike_time_samples\"].divide(fs)\n",
    "    )\n",
    "    .drop(\"spike_time_samples\", axis=1)\n",
    "    .merge(dfb[[\"cluster\", \"neuron_id\", \"session_name\", \"group_name\"]])\n",
    "    .loc[lambda x: x[\"cluster\"] != \"no_baseline\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_names = df_spiketimes[\"session_name\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0%\n",
      "50.0%\n"
     ]
    }
   ],
   "source": [
    "big_frames = []\n",
    "BINS = np.array([0.001, 0.01])\n",
    "NUM_LAGS=200\n",
    "\n",
    "for i, BIN in enumerate(BINS):\n",
    "    print(f\"{(i/len(BINS) * 100)}%\") \n",
    "    frames = []\n",
    "    for session in session_names:\n",
    "        frames.append(\n",
    "            df_spiketimes\n",
    "            .loc[lambda x: x[\"session_name\"]==session]\n",
    "            .pipe(\n",
    "                lambda x: cross_corr_test(\n",
    "                    x,\n",
    "                    binsize=BIN,\n",
    "                    num_lags=NUM_LAGS,\n",
    "                    spiketimes_col=\"spiketimes\", \n",
    "                    spiketrain_col=\"neuron_id\",\n",
    "                    use_multiprocessing=True,\n",
    "                    max_cores=10\n",
    "                )\n",
    "            )\n",
    "            .assign(session_name=session,\n",
    "                   num_lags=NUM_LAGS)\n",
    "        )\n",
    "    big_frames.append(\n",
    "        pd.concat(frames).assign(binsize=BIN)\n",
    "    )\n",
    "df = pd.concat(big_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(data_dir / \"cross_corr.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "('The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().', 'occurred at index 0')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-cc90f2280751>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m df_done = (\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mdf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdfb\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"neuron_id\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"cluster\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mleft_on\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"spiketrain_1\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mright_on\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"neuron_id\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"neuron_id\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;33m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m\"cluster\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m\"spiketrain_1_cluster\"\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\ssri\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36massign\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m   3667\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mPY36\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3668\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3669\u001b[1;33m                 \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3670\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3671\u001b[0m             \u001b[1;31m# <= 3.5: do all calculations first...\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\ssri\\lib\\site-packages\\pandas\\core\\common.py\u001b[0m in \u001b[0;36mapply_if_callable\u001b[1;34m(maybe_callable, obj, **kwargs)\u001b[0m\n\u001b[0;32m    363\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    364\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 365\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmaybe_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    366\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    367\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmaybe_callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-cc90f2280751>\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;33m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m\"cluster\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m\"spiketrain_2_cluster\"\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     .assign(has_sr=lambda x: \n\u001b[1;32m---> 10\u001b[1;33m                 x.apply(lambda y: (y.spiketrain_1_cluster == \"slow_regular\") or (y.spiketrain_2_cluster== \"slow_regular\"),\n\u001b[0m\u001b[0;32m     11\u001b[0m                        axis=1),\n\u001b[0;32m     12\u001b[0m             \u001b[0mhas_sir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\ssri\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, axis, broadcast, raw, reduce, result_type, args, **kwds)\u001b[0m\n\u001b[0;32m   6926\u001b[0m             \u001b[0mkwds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6927\u001b[0m         )\n\u001b[1;32m-> 6928\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6929\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6930\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapplymap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\ssri\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mget_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    184\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 186\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    187\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    188\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_empty_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\ssri\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m         \u001b[1;31m# compute the result using the series generator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 292\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_series_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    293\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m         \u001b[1;31m# wrap results\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\ssri\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mapply_series_generator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    319\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    320\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 321\u001b[1;33m                     \u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    322\u001b[0m                     \u001b[0mkeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-cc90f2280751>\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(y)\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;33m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m\"cluster\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m\"spiketrain_2_cluster\"\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     .assign(has_sr=lambda x: \n\u001b[1;32m---> 10\u001b[1;33m                 x.apply(lambda y: (y.spiketrain_1_cluster == \"slow_regular\") or (y.spiketrain_2_cluster== \"slow_regular\"),\n\u001b[0m\u001b[0;32m     11\u001b[0m                        axis=1),\n\u001b[0;32m     12\u001b[0m             \u001b[0mhas_sir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\ssri\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__nonzero__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1550\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__nonzero__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1552\u001b[1;33m         raise ValueError(\n\u001b[0m\u001b[0;32m   1553\u001b[0m             \u001b[1;34m\"The truth value of a {0} is ambiguous. \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1554\u001b[0m             \"Use a.empty, a.bool(), a.item(), a.any() or a.all().\".format(\n",
      "\u001b[1;31mValueError\u001b[0m: ('The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().', 'occurred at index 0')"
     ]
    }
   ],
   "source": [
    "df_done = (\n",
    "    df\n",
    "    .merge(dfb[[\"neuron_id\", \"cluster\"]], left_on=\"spiketrain_1\", right_on=\"neuron_id\")\n",
    "    .drop(\"neuron_id\", axis=1)\n",
    "    .rename(columns={\"cluster\": \"spiketrain_1_cluster\"})\n",
    "    .merge(dfb[[\"neuron_id\", \"cluster\"]], left_on=\"spiketrain_2\", right_on=\"neuron_id\")\n",
    "    .drop(\"neuron_id\", axis=1)\n",
    "    .rename(columns={\"cluster\": \"spiketrain_2_cluster\"})\n",
    "    .assign(has_sr=lambda x: \n",
    "                x.apply(lambda y: (y.spiketrain_1_cluster == \"slow_regular\") or (y.spiketrain_2_cluster== \"slow_regular\"),\n",
    "                       axis=1),\n",
    "            has_sir=lambda x: \n",
    "                x.apply(lambda y: (y.spiketrain_1_cluster == \"slow_irregular\") or (y.spiketrain_2_cluster== \"slow_irregular\"),\n",
    "                       axis=1),\n",
    "            has_ff=lambda x: \n",
    "                x.apply(lambda y: (y.spiketrain_1_cluster == \"fast_firing\") or (y.spiketrain_2_cluster== \"fast_firing\"),\n",
    "                       axis=1)\n",
    "           )\n",
    "    .assign(comb= lambda x: x.apply(lambda y: \n",
    "                                    \"sr_sr\" if y.has_sr and (not y.has_sir) and (not y.has_ff)\n",
    "                                   else \"sr_sir\" if y.has_sr and y.has_sir and (not y.has_ff)\n",
    "                                   else \"sr_ff\" if y.has_sr and (not y.has_sir) and y.has_ff\n",
    "                                   else \"sir_sir\" if (not y.has_sr) and y.has_sir and (not y.has_ff)\n",
    "                                   else \"sir_ff\" if (not y.has_sr) and y.has_sir and y.has_ff\n",
    "                                   else \"ff_ff\", axis=1\n",
    "                                   ))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_done.to_csv(data_dir / \"cross_corr.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_done = pd.read_csv(data_dir / \"cross_corr.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = (\n",
    "    df_done\n",
    "    .loc[lambda x: abs(x.time_bin) > 0.001]\n",
    "    .groupby([\"spiketrain_1\", \"spiketrain_2\", \"binsize\"])[\"p\"]\n",
    "    .idxmin()\n",
    ").values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    df_done\n",
    "    .loc[lambda x: abs(x.time_bin) > 0.001]\n",
    "    .groupby([\"spiketrain_1\", \"spiketrain_2\", \"binsize\"])[\"p\"]\n",
    "    .idxmin()\n",
    "    .reset_index()\n",
    "    .drop(\"p\", axis=1)\n",
    "    .assign(time_bin=df_done.iloc[idx].time_bin.values,\n",
    "           lowest_p=df_done.iloc[idx].p.values)\n",
    "    .merge(dfb[[\"neuron_id\", \"cluster\"]], left_on=\"spiketrain_1\", right_on=\"neuron_id\")\n",
    "    .drop(\"neuron_id\", axis=1)\n",
    "    .rename(columns={\"cluster\": \"spiketrain_1_cluster\"})\n",
    "    .merge(dfb[[\"neuron_id\", \"cluster\"]], left_on=\"spiketrain_2\", right_on=\"neuron_id\")\n",
    "    .drop(\"neuron_id\", axis=1)\n",
    "    .rename(columns={\"cluster\": \"spiketrain_2_cluster\"})\n",
    "    .assign(has_sr=lambda x: \n",
    "                x.apply(lambda y: (y.spiketrain_1_cluster == \"slow_regular\") or (y.spiketrain_2_cluster== \"slow_regular\"),\n",
    "                       axis=1),\n",
    "            has_sir=lambda x: \n",
    "                x.apply(lambda y: (y.spiketrain_1_cluster == \"slow_irregular\") or (y.spiketrain_2_cluster== \"slow_irregular\"),\n",
    "                       axis=1),\n",
    "            has_ff=lambda x: \n",
    "                x.apply(lambda y: (y.spiketrain_1_cluster == \"fast_firing\") or (y.spiketrain_2_cluster== \"fast_firing\"),\n",
    "                       axis=1)\n",
    "           )\n",
    "    .assign(comb= lambda x: x.apply(lambda y: \n",
    "                                    \"sr_sr\" if y.has_sr and (not y.has_sir) and (not y.has_ff)\n",
    "                                   else \"sr_sir\" if y.has_sr and y.has_sir and (not y.has_ff)\n",
    "                                   else \"sr_ff\" if y.has_sr and (not y.has_sir) and y.has_ff\n",
    "                                   else \"sir_sir\" if (not y.has_sr) and y.has_sir and (not y.has_ff)\n",
    "                                   else \"sir_ff\" if (not y.has_sr) and y.has_sir and y.has_ff\n",
    "                                   else \"ff_ff\", axis=1\n",
    "                                   ))\n",
    "    .to_csv(data_dir / \"cross_corr_simp.csv\", index=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
